{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due Monday, September 17 by 2:00 PM**. Submit via handin as hwk2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpful setup code. Feel free to add whatever else you might need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Predicting House Prices\n",
    "\n",
    "The `sklearn.datasets.fetch_california_housing` dataset contains information on houses in California. Let's train a model to predict house prices!\n",
    "\n",
    "More info on the data can be found [here](http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Visualize the univariate distribution (as a histogram) of each feature, and the distribution of the target. Do you notice anything? Is something that you think might require special treatment (comment what it is, youâ€™re not required to try to fix it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Visualize the dependency of the target on each feature (2d scatter plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Split data in training and test set. Evaluate Linear Regression (OLS), Ridge, Lasso and ElasticNet using cross-validation with the default parameters. Does scaling the data with StandardScaler help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Tune the parameters of the models using GridSearchCV. Do the results improve? Visualize the dependence of the validation score on the parameters for Ridge, Lasso and ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Visualize the coefficients of the resulting models. Do they agree on which features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Classifying Forest Cover Type\n",
    "\n",
    "Dataset: sklearn.datasets.fetch_covtype\n",
    "\n",
    "Details: [https://archive.ics.uci.edu/ml/datasets/covertype\n",
    "](https://archive.ics.uci.edu/ml/datasets/covertype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Visualize the univariate distribution of each feature, and the distribution of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Split data into training and test set. Evaluate Logistic Regression, linear support vector machines and nearest centroids using cross-validation. How different are the results? How does scaling the data with StandardScaler influence the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Tune the parameters using GridSearchCV. Do the results improve? Visualize the performance as function of the parameters for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Change the cross-validation strategy from 'stratified k-fold' to 'kfold' with shuffling. Do the parameters that are found change? Do they change if you change the random seed of the shuffling? Or if you change the random state of the split into training and test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Visualize the coefficients for LogisticRegression and Linear Support Vector Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Implementing kNN\n",
    "\n",
    "In class we implemented $k$-nearest neighbors with $k=1$. Let's now implement a $k$NN classifier that can use other $k$ values. In the process you'll also learn about Python's object-oriented features. The only method you'll need to finish is `predict`.\n",
    "\n",
    "Functions you may find useful:\n",
    "    - `sklearn.metrics.pairwise.euclidean_distances` or `scipy.spatial.distance.euclidean`\n",
    "    - `numpy.argpartition` to find the $k$ shortest distances. Alternatively, you could use Python `bisect` module.\n",
    "    - `numpy.bincount` and `numpy.argmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the definition of a new class for our classifier.\n",
    "# Notice the constructor is called __init__\n",
    "# All methods take in an explicit parameter \"self\". \n",
    "# It's like C++'s 'this', except in C++ it's not an explicit parameter.\n",
    "class kNNClassifier:\n",
    "    # We don't actually need to do any initialization, so just \"pass\"\n",
    "    def __init__(self, k):\n",
    "        # Setting a member variable is as simple as assigning one. You don't even need to declare it anywhere.\n",
    "        self.n_neighbors = k\n",
    "    \n",
    "    # Remember we don't need to do much here except save the data.\n",
    "    # We'll assume our data is in the form of a numpy multidimensional array.\n",
    "    def fit(self, data, target):\n",
    "        self.data = data\n",
    "        self.labels = target\n",
    "    \n",
    "    # Take in some data points X and return a numpy array of predictions.\n",
    "    def predict(self, X):\n",
    "        k = self.n_neighbors\n",
    "        predictions = []\n",
    "        # CODE HERE\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

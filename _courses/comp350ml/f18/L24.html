<!DOCTYPE html>
<html lang="python">
<head>
<meta charset="utf-8"/>
<title>Applied Machine Learning</title>
<meta name="author" content="(Robert Utterback)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/reveal.js/3.0.0/css/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/reveal.js/3.0.0/css/theme/white.css" id="theme"/>

<link rel="stylesheet" href="./notes.css"/>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/reveal.js/3.0.0/lib/css/zenburn.css"/>
<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'https://cdn.jsdelivr.net/reveal.js/3.0.0/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
\(
\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\E}{\mathop{\boldsymbol{E}}}
\newcommand{\var}{\boldsymbol{Var}}
\newcommand{\norm}[1]{\lvert\lvert#1\rvert\rvert}
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\ltwo}[1]{\norm{#1}_2}
\newcommand{\lone}[1]{\norm{#1}_1}
\newcommand{\sgn}[1]{\text{sign}\left( #1 \right)}
\newcommand{\e}{\mathrm{e}}
\newcommand{\minw}{\min_{w \in \mathbb{R}^p}}
\newcommand{\sumn}{\sum_{i=1}^n}
\newcommand{\logloss}{\log{(\exp{(-y_iw^T\vec{x}_i)} + 1)}}
\)

<section>
<section id="slide-org6205e75">
<h2 id="org6205e75">Ensemble Models and Gradient Boosting</h2>
<p>
Robert Utterback
</p>

<p>
Based on slides by Andreas Müller
</p>
<aside class="notes">
<p>
Start off with ensemble models in general, then talk about gradient boosting.
</p>

</aside>
</section>
</section>
<section>
<section id="slide-orge20ca15">
<h2 id="orge20ca15">Ensemble Models</h2>
<aside class="notes">
<p>
The general term that captures any way of turning multiple models into one.
</p>

</aside>
</section>
<section id="slide-org955fc6f">
<h3 id="org955fc6f">Poor man's ensembles</h3>
<ul>
<li>Build different models</li>
<li>Average the result</li>
<li>Owen Zhang (long time kaggle 1st): build XGBoosting models with different random seeds.</li>
<li>More models are better – if they are not correlated.</li>
<li>Also works with neural networks</li>
<li>You can average any models as long as they provide calibrated ("good") probabilities.</li>
<li>Scikit-learn: VotingClassifier hard and soft voting</li>

</ul>
<aside class="notes">
<p>
Just build same model multiple times with multiple random seeds, and
average the results.  Not used as much in practice &#x2014; gives a few
extra points of accuracy, but can take a while and makes it very hard
to interpret.
soft: average probs, do argmax
Hard: take the thing most commonly predicted
</p>

</aside>
</section>
<section id="slide-org71e9160">
<h3 id="org71e9160">VotingClassifier</h3>
<div class="org-src-container">

<pre id="smallcode"><code class="python" >voting = VotingClassifier(
    [('logreg', LogisticRegression(C=100)),
     ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))],
    voting='soft')
voting.fit(X_train, y_train)
lr, tree = voting.estimators_
voting.score(X_test, y_test), lr.score(X_test, y_test), \
    tree.score(X_test, y_test)
</code></pre>
</div>

<div class="figure">
<p><img src="./assets/voting_classifier.png" alt="voting_classifier.png" height="300px" />
</p>
</div>
<aside class="notes">
<p>
Left: logreg, middle: single tree, right: voting using both
</p>

<p>
If they overfit in the same way, you're not getting rid of the overfitting
</p>

<p>
So you want to make sure they're different
</p>

</aside>
</section>
<section id="slide-org8316cd6">
<h3 id="org8316cd6">Bagging (Bootstrap Aggregation)</h3>
<div class="column" style="float:left; width: 50%">
<ul>
<li>Generic way to build “slightly different” models</li>
<li><code>BaggingClassifier, BaggingRegressor</code></li>

</ul>
</div>
<div class="column" style="float:left; width: 50%">

<div class="figure">
<p><img src="./assets/tree_datasplit.png" alt="tree_datasplit.png" />
</p>
</div>
</div>
<aside class="notes">
<ul>
<li>Want to build similar models but ensure they are different (more than just random seed)</li>
<li>Draw bootstrap samples from dataset (sample with replacement)</li>
<li>Bootstrap AGgregation</li>
<li>(as many as there are in the dataset, with repetition)</li>
<li>Some data is left out, some is duplicated == slightly different dataset</li>
<li>Then average models, might not overfit as much</li>

</ul>

</aside>
</section>
<section id="slide-org0d81bf1">
<h3 id="org0d81bf1">Bias and Variance</h3>

<div class="figure">
<p><img src="./assets/bias-variance.png" alt="bias-variance.png" height="400px" />
</p>
</div>

<p>
<a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">http://scott.fortmann-roe.com/docs/BiasVariance.html</a>
</p>
<aside class="notes">
<p>
Often talked about in bagging context. Bagging takes multiple high
variance models and can reduce them. If predictions are not
correlated, there's a proof that we get a low variance estimator.
</p>

<ul>
<li>high bias, low variance: very consistent predictions, but off (low variance linear model, underfitting)</li>
<li>low bias, low variance: captures the data very well, low variance in predictions</li>
<li>high variance, low bias: predictions good on average, but high variance</li>
<li>high variance, high bias: well just bad overall</li>

</ul>

</aside>
</section>
<section id="slide-org2386a2f">
<h3 id="org2386a2f">Bias and Variance in Ensembles</h3>
<ul>
<li>Breiman showed that generalization depends on strength of the
individual classifiers and (inversely) on their correlation</li>
<li>Uncorrelating them might help, even at the expense of strength</li>

</ul>
<aside class="notes">
<p>
Sometimes do even more randomization, even if it makes prediction
worse! Helps if you have a lot of models. Hence random forests.
</p>

</aside>

</section>
</section>
<section>
<section id="slide-org929eeab">
<h2 id="org929eeab">Boosting (in General)</h2>
<aside class="notes">
<p>
One of the best off-the-shelf methods. Builds off of trees.
</p>

<p>
We'll continue on with the techniques of stacking and calibration.
</p>

<p>
Gradient boosting is one of the most successfull supervised machine learning methods in practice.
It's often used in kaggle to win competition, it's used for credit scoring, it's one of the standard tools of the trade.
It's one of the best of-the-shelf models.
A standard implementation that people use is XGBoost, but there's also an implementation in scikit-learn, and we'll talk about both of them.Last time we talked about Random forests, which builds many trees independently, each randomized in a different way, and then averages their predictions.
Gradient boosting on the other hand builds trees one by one in a sequential manner, with each tree requiring the results of previous trees.
Often, Gradient boosting is done with very small trees, or even decision stumps, which is trees of depth one, so a single split.
</p>

<ul>
<li>"Meta-algorithm" (similar to bagging) to create strong learners from weak learners.</li>
<li>Tries to iteratively improve these simple (weak) models</li>
<li>AdaBoost, GentleBoost, …</li>
<li>Small  Trees or stumps work best</li>
<li>Gradient Boosting often the best of the bunch, so we won't talk
other types of boosting (or using other learners)</li>
<li>Many specialized algorithms (ranking etc)</li>

</ul>

<p>
This is an instance of a more general family of models, called boosting models, which all iteratively
try to improve a model built up from weak learners. Gradient boosting is this particular technique
where we are trying to fit the residuals, and it's been found to work very well in practice, in particular
if you're using shallow trees as the weak learners.
In principle, you could use any model as a weak learner, but trees just work really well.
</p>

</aside>
</section>
<section id="slide-org1653d9e">
<h3 id="org1653d9e">Gradient Boosting Algorithm</h3>
<p>
\[ f_{1}(x) \approx y  \]
\[ f_{2}(x) \approx y - f_{1}(x) \]
\[ f_{3}(x) \approx y - f_{1}(x) - f_{2}(x)\]
</p>

<div class="smallimgs">
<p>
\(y \approx\) <img src="./assets/grad_boost_term_1.png" alt="grad_boost_term_1.png" /> +  <img src="./assets/grad_boost_term_2.png" alt="grad_boost_term_2.png" /> + <img src="./assets/grad_boost_term_3.png" alt="grad_boost_term_3.png" /> + &#x2026;
</p>
</div>
<aside class="notes">
<ul>
<li>Let's look at the regression case first.</li>
<li>We start by building a single tree f1 to try to predict the output
y. But we strongly restrict f1 (shallow), so it will be rather bad at
predicting y.</li>
<li>Next, we'll look at the residual of this first model, so y - f1(x).</li>
<li>We now train a new model f2 to try and predict this residual, in
other words to correct the mistakes made by f1. Again, this will be
a very simple model, so it will still not be able to fix all errors.</li>
<li>Then, we look at the residual of both of the models together, so y -
f1(x) - f2(x), so the mistakes that could not be fixed by f2, and we
build f3 to fix that, and so on.</li>
<li>To make predictions you just add up all the predictions. Note you
add, not average, like RF. Also in random forests each tree is
independent.</li>
<li>This is natural for regression. For classification this is not as clear.</li>
<li>For binary classification you use log-loss, or rather you apply the
logistic function to get a binary prediction, for multi-class you
can use 1 vs rest.</li>
<li>So we're sequentially building up a model using what's called "weak
learners", small trees, and create a more powerful composite model.</li>

</ul>

</aside>
</section>
<section id="slide-org8377955">
<h3 id="org8377955">Learning Rate</h3>
<p>
\(f_{1}(x) \approx y\)
\(f_{2}(x) \approx y - \alpha f_{1}(x)\)
\(f_{3}(x) \approx y - \alpha f_{1}(x) - \alpha f_{2}(x)\)
</p>

<div class="smallimgs">
<p>
\(y \approx \alpha\) <img src="./assets/grad_boost_term_1.png" alt="grad_boost_term_1.png" /> + \(\alpha\) <img src="./assets/grad_boost_term_2.png" alt="grad_boost_term_2.png" /> + \(\alpha\) <img src="./assets/grad_boost_term_3.png" alt="grad_boost_term_3.png" /> + &#x2026;
</p>
</div>

<p>
Learning rate \(\alpha, i.e. 0.1\)
</p>
<aside class="notes">
<ul>
<li>Q: If I didn't restrict my tree at all and set \(\alpha=1\), what would \(y-f_{1}(x)\) be? A: 0!</li>
<li>Discount update by learning rate, kind of like saying you don't trust it fully.</li>
<li>Only taking a small step in the direction of \(f_i\)</li>
<li>Kind of like gradient descent if you squint (really hard)</li>
<li>Each tree can only take a small step, so smaller learning rates =
you need more trees</li>
<li>In gradient boosting, adding more trees increases chance of
overfitting, so isn't as good as adding trees in RF.</li>
<li>Use log loss for classification</li>

</ul>

</aside>
</section>
<section id="slide-orgb630cb1">
<h3 id="orgb630cb1">GradientBoostingRegressor</h3>

<div class="figure">
<p><img src="./assets/grad_boost_regression_steps.png" alt="grad_boost_regression_steps.png" height="500px" />
</p>
</div>
<aside class="notes">
<p>
First fit shallow tree to data. Right side is squished by alpha.  Now
below on the left the dots move, they are the residuals. Then fit a
tree again, and again look at predictions squished by alpha. And so on.
</p>

</aside>
</section>
<section id="slide-org503c9c7">
<h3 id="org503c9c7">GradientBoostingClassifier</h3>

<div class="figure">
<p><img src="./assets/grad_boost_depth2.png" alt="grad_boost_depth2.png" />
</p>
</div>
<aside class="notes">
<p>
Basically applying log loss, trying to find regression function that
has smallest log loss, but f is the decision function.
</p>

<p>
White means a tie, probability 0.5.
</p>

</aside>
</section>
<section id="slide-org38f4849">
<h3 id="org38f4849">Gradient Boosting Advantages</h3>
<ul>
<li>Slower to train than RF (serial), but much faster to predict</li>
<li>Small model size</li>
<li>Typically more accurate than Random Forests</li>

</ul>
</section>
<section id="slide-org07de7a4">
<h3 id="org07de7a4">Tuning Gradient Boosting</h3>
<ul>
<li>Pick n_estimators, tune learning rate</li>
<li>Can also tune max_features</li>
<li>Typically strong pruning via max_depth</li>

</ul>
<aside class="notes">
<p>
Commonly people will just pick n_estimators that you have time to
train for. Maybe tune learning rate over that, but you can also tune
max_features, or use subsampling.
</p>

<p>
Often depth much smaller than RF, which means less memory and faster prediction
</p>

</aside>
</section>
</section>
<section>
<section id="slide-orgbd90abb">
<h2 id="orgbd90abb">Analyzing Gradient Boosting</h2>
<div class="outline-text-2" id="text-orgbd90abb">
</div>
</section>
<section id="slide-org2d882c5">
<h3 id="org2d882c5">Partial Dependence Plots</h3>
<ul>
<li>Marginal dependence of prediction on one or two features</li>

</ul>
<div class="org-src-container">

<pre id="smallcode"><code class="python" >from sklearn.ensemble.partial_dependence import plot_partial_dependence
boston = load_boston()
X_train, X_test, y_train, y_test = \
    train_test_split(boston.data, boston.target,
                     random_state=0)

gbrt = GradientBoostingRegressor().fit(X_train, y_train)

fig, axs = \
    plot_partial_dependence(gbrt, X_train,
                            np.argsort(gbrt.feature_importances_)[-6:],
                            feature_names=boston.feature_names, n_jobs=3,
                            grid_resolution=50)
</code></pre>
</div>

<aside class="notes">
<p>
In sklearn right now only for gradient boosting, not all trees.
</p>

<p>
Idea: see not just which params are important, but how they influence the target.
</p>

<p>
This takes 6 most important features.
</p>

</aside>
</section>
<section id="slide-orgb5c9805">
<h3 id="orgb5c9805">Partial Dependence Plots</h3>

<div class="figure">
<p><img src="./assets/feat_impo_part_dep.png" alt="feat_impo_part_dep.png" />
</p>
</div>
<aside class="notes">
<ul>
<li>The marginal contribution of each feature.</li>
<li>Basically how does the target change based on the feature.</li>
<li>RM is most important, goes left.</li>
<li>Look at only the contribution of this particular feature.</li>
<li>For most models this is hard to compute, but can do efficiently for trees.</li>

</ul>

</aside>
</section>
<section id="slide-orgd53a2b6">
<h3 id="orgd53a2b6">Bivariate Partial Dependence Plots</h3>
<div class="org-src-container">

<pre><code class="python" >plot_partial_dependence(
    gbrt, X_train, [np.argsort(gbrt.feature_importances_)[-2:]],
    feature_names=boston.feature_names,
    n_jobs=3, grid_resolution=50)
</code></pre>
</div>

<div class="figure">
<p><img src="./assets/feature_importance.png" alt="feature_importance.png" />
</p>
</div>
<aside class="notes">
<p>
Can also look at interactions between features. Looks like nothing too strong here.
</p>

<p>
It's kind of hard to tell. If you take the two feature plots before
and do the "outer" product, this is basically what you expect. A rule
of thumb is that it's all basically going in the same direction. (?)
</p>

</aside>
</section>
<section id="slide-orgd2958c6">
<h3 id="orgd2958c6">Partial Dependence for Classification</h3>
<div class="org-src-container">

<pre id="tinycode"><code class="python" >from sklearn.ensemble.partial_dependence import plot_partial_dependence
for i in range(3):
    fig, axs = \
        plot_partial_dependence(gbrt, X_train, range(4), n_cols=4,
                                feature_names=iris.feature_names,
                                grid_resolution=50, label=i)
</code></pre>
</div>

<div class="figure">
<p><img src="./assets/feat_impo_part_dep_class.png" alt="feat_impo_part_dep_class.png" height="400px" />
</p>
</div>
<aside class="notes">
<p>
Same for classification. Note we have a classifier for each class b/c we're using OVR.
</p>

</aside>
</section>
</section>
<section>
<section id="slide-org5a6aca5">
<h2 id="org5a6aca5">Practical details</h2>
<div class="outline-text-2" id="text-org5a6aca5">
</div>
</section>
<section id="slide-org1bb4cc2">
<h3 id="org1bb4cc2">XGBoost</h3>
<p>
conda install -c conda-forge xgboost
</p>
<div class="org-src-container">

<pre><code class="python" >from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train, y_train)
xgb.score(X_test, y_test)
</code></pre>
</div>
<ul>
<li>supports missing values</li>
<li>supports multi-core (sklearn does not)</li>

</ul>
<aside class="notes">
<ul>
<li>Efficient implementation of gradient boosting (5x sklearn)</li>
<li>Improvements on original algorithm</li>
<li>Adds l1 and l2 penalty on leaf-weights</li>
<li>Fast approximate split finding</li>
<li>Scikit-learn compatible interface</li>

</ul>

</aside>
</section>
<section id="slide-org3a52e41">
<h3 id="org3a52e41"></h3>

<div class="figure">
<p><img src="./assets/xgboost_sklearn_bench.png" alt="xgboost_sklearn_bench.png" height="350px" />
</p>
</div>

<ul>
<li>Exact splits ~5x faster on single core</li>
<li>Approximate splits (bin the features, don't sort them), multi-core \(\to\) more speed!</li>
<li>Also check lightGBM (even faster?)</li>

</ul>
<aside class="notes">
<ul>
<li>Better benchmarks available online</li>
<li>x axis is number of samples</li>
<li>y axis is time</li>
<li>lightGBM is from Microsoft</li>
<li>Both have GPU support</li>

</ul>

</aside>
</section>
<section id="slide-org12c0f92">
<h3 id="org12c0f92">Early stopping</h3>
<ul>
<li>Adding trees can lead to overfitting</li>
<li>Stop adding trees when validation accuracy stops increasing</li>
<li>Optional in XGBoost and sklearn \(\ge\) 0.20 (development)</li>

</ul>
<aside class="notes">
<p>
Idea: pick large # estimators, once validation accuracy stops improving, stop.
Needs a validation set, so you have less data for training. Must still have a test set, though&#x2026;
</p>

</aside>
</section>
<section id="slide-org6b55aa1">
<h3 id="org6b55aa1">When to use tree-based models</h3>
<ul>
<li>Model non-linear relationships</li>
<li>Doesn’t care about scaling, no need for feature engineering</li>
<li>Single tree: very interpretable (if small)</li>
<li>Random forests: very robust, good benchmark</li>
<li>Gradient boosting often best performance with careful tuning</li>

</ul>
<aside class="notes">
<p>
Summary. Great for lots of weird features.
</p>

<p>
Very high dimensional, sparse data: probably not trees
</p>

</aside>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/reveal.js/3.0.0/lib/js/head.min.js"></script>
<script src="https://cdn.jsdelivr.net/reveal.js/3.0.0/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: 'c/t',
rollingLinks: false,
keyboard: true,
overview: true,
margin: 0.05,
minScale: 0.20,
maxScale: 15.00,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: '0.0',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'https://cdn.jsdelivr.net/reveal.js/3.0.0/lib/js/classList.js', condition: function() { return !document.body.classList; } },
 { src: 'https://cdn.jsdelivr.net/reveal.js/3.0.0/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'https://cdn.jsdelivr.net/reveal.js/3.0.0/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'https://cdn.jsdelivr.net/reveal.js/3.0.0/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
 { src: 'https://cdn.jsdelivr.net/reveal.js/3.0.0/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: 'https://cdn.jsdelivr.net/reveal.js/3.0.0/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
,pdfSeparateFragments: false});
</script>
</body>
</html>
